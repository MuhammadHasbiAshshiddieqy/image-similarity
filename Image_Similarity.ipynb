{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONwwfBTWH4im5ZveJ04RgX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadHasbiAshshiddieqy/image-similarity/blob/master/Image_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dino V2\n",
        "\n",
        "https://towardsai.net/p/machine-learning/vision-embedding-comparison-for-image-similarity-search-efficientnet-vs-vit-vs-vino-vs-clip-vs-blip2"
      ],
      "metadata": {
        "id": "tvLIxyfrIN_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk4t3COCIDGi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from transformers import AutoModel\n",
        "\n",
        "class BagSimilarityDetector:\n",
        "    def __init__(self):\n",
        "        print(\"Initializing DINOv2 model for bag similarity detection...\")\n",
        "        # Using DINOv2 model which excels at visual feature extraction\n",
        "        self.model_name = \"facebook/dinov2-base\"\n",
        "        self.model = AutoModel.from_pretrained(self.model_name)\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Set up image transformation pipeline (DINOv2 expects 224x224 images)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        print(f\"Model loaded successfully. Using device: {self.device}\")\n",
        "\n",
        "        # List of bag attributes to test specifically\n",
        "        self.bag_attributes = [\n",
        "            \"a designer handbag\",\n",
        "            \"a tote bag\",\n",
        "            \"a crossbody bag\",\n",
        "            \"a clutch bag\",\n",
        "            \"a backpack\",\n",
        "            \"a bag with leather material\",\n",
        "            \"a bag with canvas material\",\n",
        "            \"a bag with pattern\",\n",
        "            \"a bag with solid color\",\n",
        "            \"a bag with logo print\",\n",
        "            \"a structured bag\",\n",
        "            \"a soft bag\"\n",
        "        ]\n",
        "\n",
        "    def preprocess_image(self, img_path):\n",
        "        \"\"\"Preprocess image for DINOv2\"\"\"\n",
        "        # Read image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Cannot read image at {img_path}\")\n",
        "\n",
        "        # Convert to RGB (DINOv2 expects RGB format)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Convert to PIL Image\n",
        "        pil_img = Image.fromarray(img)\n",
        "\n",
        "        # Apply transformations\n",
        "        tensor_img = self.transform(pil_img).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "        return tensor_img, pil_img\n",
        "\n",
        "    def extract_visual_features(self, img_path):\n",
        "        \"\"\"Extract visual features using DINOv2\"\"\"\n",
        "        try:\n",
        "            # Preprocess image\n",
        "            tensor_img, _ = self.preprocess_image(img_path)\n",
        "            tensor_img = tensor_img.to(self.device)\n",
        "\n",
        "            # Extract visual features\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(tensor_img)\n",
        "\n",
        "            # Use the [CLS] token features which contains global image representation\n",
        "            image_features = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
        "\n",
        "            # Normalize features\n",
        "            normalized_features = image_features / np.linalg.norm(image_features, axis=1, keepdims=True)\n",
        "\n",
        "            return normalized_features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting features: {e}\")\n",
        "            return None\n",
        "\n",
        "    def analyze_specific_attributes(self, img_path):\n",
        "        \"\"\"Analyze specific bag attributes\"\"\"\n",
        "        try:\n",
        "            # Read and preprocess the image\n",
        "            _, pil_img = self.preprocess_image(img_path)\n",
        "            img = np.array(pil_img)\n",
        "\n",
        "            # Resize for consistency\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "\n",
        "            # Calculate basic visual statistics for attribute approximation\n",
        "\n",
        "            # Color analysis (for solid color vs pattern)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            color_variance = np.std(img, axis=(0, 1)).mean()\n",
        "            texture_variance = np.std(gray)\n",
        "\n",
        "            # Edge detection (for structured vs soft bag)\n",
        "            edges = cv2.Canny(gray, 50, 150)\n",
        "            edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])\n",
        "\n",
        "            # Color distribution (for material approximation)\n",
        "            hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "            saturation = np.mean(hsv[:,:,1])\n",
        "            brightness = np.mean(hsv[:,:,2])\n",
        "\n",
        "            # Shape analysis (for bag type approximation)\n",
        "            height, width = img.shape[:2]\n",
        "            aspect_ratio = width / height\n",
        "\n",
        "            # Create simulated attribute scores\n",
        "            attribute_scores = {}\n",
        "\n",
        "            # Bag type scores based on aspect ratio and edge density\n",
        "            attribute_scores[\"a tote bag\"] = 0.5 + 0.3 * (1 - abs(aspect_ratio - 0.9)) - 0.2 * edge_density\n",
        "            attribute_scores[\"a crossbody bag\"] = 0.5 + 0.3 * (1 - abs(aspect_ratio - 0.7)) - 0.1 * edge_density\n",
        "            attribute_scores[\"a clutch bag\"] = 0.5 + 0.3 * (1 - abs(aspect_ratio - 1.8)) + 0.1 * edge_density\n",
        "            attribute_scores[\"a backpack\"] = 0.5 + 0.3 * (1 - abs(aspect_ratio - 0.6)) + 0.2 * edge_density\n",
        "            attribute_scores[\"a designer handbag\"] = 0.5 + 0.1 * edge_density + 0.2 * saturation\n",
        "\n",
        "            # Material scores based on texture, saturation and brightness\n",
        "            attribute_scores[\"a bag with leather material\"] = 0.5 + 0.2 * saturation - 0.1 * texture_variance\n",
        "            attribute_scores[\"a bag with canvas material\"] = 0.5 - 0.1 * saturation + 0.2 * texture_variance\n",
        "\n",
        "            # Pattern scores based on variance\n",
        "            attribute_scores[\"a bag with pattern\"] = 0.5 + 0.3 * (color_variance / 80)\n",
        "            attribute_scores[\"a bag with solid color\"] = 0.5 + 0.3 * (1 - color_variance / 80)\n",
        "            attribute_scores[\"a bag with logo print\"] = 0.5 + 0.2 * edge_density + 0.1 * (color_variance / 80)\n",
        "\n",
        "            # Structure scores based on edge density\n",
        "            attribute_scores[\"a structured bag\"] = 0.5 + 0.4 * edge_density\n",
        "            attribute_scores[\"a soft bag\"] = 0.5 + 0.4 * (1 - edge_density)\n",
        "\n",
        "            # Normalize all scores to range [0, 1]\n",
        "            for attr in attribute_scores:\n",
        "                attribute_scores[attr] = max(0, min(1, attribute_scores[attr]))\n",
        "\n",
        "            return attribute_scores\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing attributes: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def compare_bags(self, img_path1, img_path2):\n",
        "        \"\"\"Compare two bag images using DINOv2\"\"\"\n",
        "        print(f\"Comparing bags: {img_path1} and {img_path2}\")\n",
        "\n",
        "        # Extract visual features\n",
        "        features1 = self.extract_visual_features(img_path1)\n",
        "        features2 = self.extract_visual_features(img_path2)\n",
        "\n",
        "        if features1 is None or features2 is None:\n",
        "            print(\"Failed to extract features from one or both images\")\n",
        "            return None, None, None\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        visual_similarity = np.dot(features1, features2.T)[0][0]\n",
        "\n",
        "        # Analyze specific attributes\n",
        "        attributes1 = self.analyze_specific_attributes(img_path1)\n",
        "        attributes2 = self.analyze_specific_attributes(img_path2)\n",
        "\n",
        "        # Calculate attribute similarity\n",
        "        attribute_similarities = {}\n",
        "        for attr in self.bag_attributes:\n",
        "            score1 = attributes1.get(attr, 0)\n",
        "            score2 = attributes2.get(attr, 0)\n",
        "            # The closer the attribute values, the higher the similarity\n",
        "            attr_sim = 1 - abs(score1 - score2)\n",
        "            attribute_similarities[attr] = attr_sim\n",
        "\n",
        "        # Calculate average attribute similarity\n",
        "        avg_attr_similarity = sum(attribute_similarities.values()) / len(attribute_similarities)\n",
        "\n",
        "        # Weighted similarity (80% visual, 20% attribute)\n",
        "        weighted_similarity = 0.8 * visual_similarity + 0.2 * avg_attr_similarity\n",
        "\n",
        "        return visual_similarity, attribute_similarities, weighted_similarity\n",
        "\n",
        "    def create_comparison_visualization(self, img_path1, img_path2, visual_similarity, attribute_similarities, weighted_similarity):\n",
        "        \"\"\"Create visualization for bag comparison\"\"\"\n",
        "        # Prepare images\n",
        "        img1 = cv2.imread(img_path1)\n",
        "        img2 = cv2.imread(img_path2)\n",
        "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Resize images if too large\n",
        "        max_height = 400\n",
        "        if img1.shape[0] > max_height:\n",
        "            scale = max_height / img1.shape[0]\n",
        "            img1 = cv2.resize(img1, (int(img1.shape[1] * scale), max_height))\n",
        "        if img2.shape[0] > max_height:\n",
        "            scale = max_height / img2.shape[0]\n",
        "            img2 = cv2.resize(img2, (int(img2.shape[1] * scale), max_height))\n",
        "\n",
        "        # Create plot\n",
        "        plt.figure(figsize=(14, 10))\n",
        "\n",
        "        # Plot bag images\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.imshow(img1)\n",
        "        plt.title(\"Tas 1\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.imshow(img2)\n",
        "        plt.title(\"Tas 2\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot overall similarity\n",
        "        plt.subplot(2, 2, 3)\n",
        "        similarity_labels = ['Visual Similarity', 'Attribute Similarity', 'Weighted Similarity']\n",
        "        similarity_values = [visual_similarity, sum(attribute_similarities.values())/len(attribute_similarities), weighted_similarity]\n",
        "        plt.bar(similarity_labels, similarity_values, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
        "        plt.ylim(0, 1)\n",
        "        plt.title(\"Overall Similarity Metrics\")\n",
        "        plt.ylabel(\"Similarity Score\")\n",
        "\n",
        "        # Plot attribute similarities\n",
        "        plt.subplot(2, 2, 4)\n",
        "\n",
        "        # Show top 5 attributes with highest similarity\n",
        "        sorted_attributes = sorted(attribute_similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_attrs = sorted_attributes[:5]\n",
        "\n",
        "        # Use shorter labels for the plot\n",
        "        top_labels = [attr.replace(\"a bag with \", \"\").replace(\"a \", \"\") for attr, _ in top_attrs]\n",
        "        top_values = [value for _, value in top_attrs]\n",
        "\n",
        "        plt.barh(top_labels, top_values, color='#2ecc71')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.title(\"Top 5 Attribute Similarities\")\n",
        "        plt.xlabel(\"Similarity Score\")\n",
        "\n",
        "        # Add overall description\n",
        "        similarity_category = \"\"\n",
        "        if weighted_similarity >= 0.85:\n",
        "            similarity_category = \"Sangat mirip\"\n",
        "        elif weighted_similarity >= 0.7:\n",
        "            similarity_category = \"Mirip\"\n",
        "        elif weighted_similarity >= 0.5:\n",
        "            similarity_category = \"Agak mirip\"\n",
        "        else:\n",
        "            similarity_category = \"Tidak mirip\"\n",
        "\n",
        "        plt.figtext(0.5, 0.01, f\"Overall Similarity: {weighted_similarity:.4f} ({similarity_category})\",\n",
        "                   ha=\"center\", fontsize=14, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(bottom=0.1)\n",
        "\n",
        "        # Save image\n",
        "        result_dir = \"comparison_results\"\n",
        "        os.makedirs(result_dir, exist_ok=True)\n",
        "        result_path = os.path.join(result_dir, f\"comparison_{os.path.basename(img_path1)}_{os.path.basename(img_path2)}.png\")\n",
        "        plt.savefig(result_path)\n",
        "        print(f\"Saved comparison visualization to {result_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        return result_path\n",
        "\n",
        "def main():\n",
        "    # Initialize detector\n",
        "    detector = BagSimilarityDetector()\n",
        "    img_1 = \"tas1.jpeg\"\n",
        "    img_2 = \"tas1.jpeg\"\n",
        "\n",
        "    # Compare bags\n",
        "    visual_similarity, attribute_similarities, weighted_similarity = detector.compare_bags(img_1, img_2)\n",
        "\n",
        "    if visual_similarity is None:\n",
        "        print(\"Comparison failed.\")\n",
        "        return\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n===== HASIL PERBANDINGAN =====\")\n",
        "    print(f\"Visual Similarity: {visual_similarity:.4f}\")\n",
        "\n",
        "    print(\"\\nAttribute Similarities:\")\n",
        "    for attr, score in sorted(attribute_similarities.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"  - {attr}: {score:.4f}\")\n",
        "\n",
        "    print(f\"\\nWeighted Similarity: {weighted_similarity:.4f}\")\n",
        "\n",
        "    # Categorize similarity\n",
        "    if weighted_similarity >= 0.85:\n",
        "        print(\"Kesimpulan: Kedua tas sangat mirip\")\n",
        "    elif weighted_similarity >= 0.7:\n",
        "        print(\"Kesimpulan: Kedua tas mirip\")\n",
        "    elif weighted_similarity >= 0.5:\n",
        "        print(\"Kesimpulan: Kedua tas agak mirip\")\n",
        "    else:\n",
        "        print(\"Kesimpulan: Kedua tas tidak mirip\")\n",
        "\n",
        "    # Create visualization\n",
        "    detector.create_comparison_visualization(img_1, img_2,\n",
        "                                          visual_similarity, attribute_similarities,\n",
        "                                          weighted_similarity)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}